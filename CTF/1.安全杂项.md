# 一.常见编码和解码
## 1.ASCII
```
ASCII（American Standard Code for Information Interchange，美国信息交换标准代码）编码（简称ASCII码）是基于拉丁字母的一套计算机编码方案，主要用于显示现代英语和其他西欧语言。它是最通用的信息交换标准，等同于国际标准ISO/IEC 646。
在计算机中，所有数据都要使用二进制数表示。字母、数字以及一些常用符号（*、#、@等）也要通过二进制数表示，不同的二进制数表示不同的符号。为了约定字符（符号）和二进制数之间的对应关系（也就是编码），美国的标准化组织制定了ASCII码，规定了常用符号用哪些二进制数来表示。ASCII码的最初构想是用7位（也称为比特，bit）表示一个字符（符号），因此一共可以表示128(0～127)个字符。在后来的使用过程中，人们倾向于用一个字节表示一个字符，一个字节是8位，所以将ASCII码扩展为8位，扩展后的ASCII码可以表示256个字符。标准ASCII码也称为基础ASCII码，使用7位二进制数（剩下的1位二进制数为0）来表示所有大写和小写字母、数字、标点符号，以及在美式英语中使用的特殊控制字符。
```
**在十六进制中，两个字符表示一个字节**
## 2.Base64编码
在扩展的ASCII码中，每个字符用一个字节表示，在不考虑正负号的情况下，一个字节可以表示的范围是0～255(0x00～0xFF)，其中0～31以及127～255都是不可打印字符。当传输这些不可打印字符时，很可能出现字符丢失或者转义错误的情况。为了有效地传输和显示这些信息，就**需要把不可打印字符转换为可打印字符**，Base64编码就是这样一种转换方案。
可以看出，Base64编码本身并不具有加密性和保密性，无法作为加密算法使用（**切记！！！**）。因此，**不要将敏感明文内容进行Base64编码后传输**，也不建议把Base64编码读作“Base64加密”。Base64编码使用64个可见字符表示所有数据。其编码原理是把原始数据按**3个字节为一组进行分割**，再将每组的3个8比特数据切分为4个6比特数据，然后根据Base64编码的标准索引表将6比特数据转换为对应的字符。Base64编码的标准索引表如表1.1.1所示。
**注意：Base64编码的标准索引表的字符顺序是大写字母、小写字母、数字、加号和斜杠(/)，等号(=)并不在索引表中。**
![image-20240725103313504](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725103313504.png)
![image-20240725103342512](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725103342512.png)
### 示例：字符串（fla)被编码“Zmxh"
![image-20240725105400508](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725105400508.png)
经过上述步骤，字符串“fla”被编码为“Zmxh”。（这个结果要求背诵并默写！）
但是，在实际转换过程中，原始数据的长度不一定恰好能被3整除，按**3**字节为一组进行分组后，最后一组会出现只有1字节或2字节的情况。这种情况下，一般默认填充0，使最后一组的长度也达到3字节。下面给出了一个例子。
![image-20240725105518264](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725105518264.png)
其中，“=”表示填充，如果填充4比特的0，编码后就有2个等号；如果只填充2比特的0，编码后有1个等号；如果没有填充0，就不会有等号。所以，**在Base64编码后的字符串中，最多只有2个等号**。
**对“fla”进行Base64编码后的结果是“Zmxh”，这个结果需要大家牢记。在很多CTF比赛中，flag的提交格式都是“flag{}”，如果发现“Zmxh”，那么很可能就找到了正确的flag**。
Base64的解码过程和编码过程类似，首先查Base64编码的标准索引表，将信息转换为二进制数据，根据等号数量确定丢弃的比特的范围（即上例中的带有下划线的部分，2个等号意味着丢弃4比特信息；1个等号意味着丢弃2比特信息），再以8比特为一组恢复出原始数据。在Koczkatamas工具包中将Base64字符串复制到B64行，即可在第一行(ASCII)看到解码后的内容
### Base64编码的“奇特”考点
​			Base64信息隐藏
![image-20240725105600554](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725105600554.png)
不难发现，不同的Base64编码的字符串在解码后对应同一个字符串。出现这种情况的原因是默认情况下会填充比特0，但在实践中完全可以填充其他比特值。在解码时，会先丢弃下划线部分填充的比特，再恢复出原始数据，下划线部分填充任意数据都不会影响Base64的解码结果。因此，只要是有等号的Base64编码的字符串都可以隐藏信息，其隐藏的规律是：**1个等号可以隐藏2比特信息，2个等号可以隐藏4比特信息。**
## 3.Base32编码
Base32编码与Base64编码类似，它使用32个可见字符表示所有数据。其编码原理是把原始数据按**每5字节分为一组**，将每组的**5**个8比特数据切分为8个5比特数据，然后根据Base32编码的标准索引表将5比特数据转换为对应的字符。填充仍然用“=”表示。Base32编码的标准索引表
![image-20240725105848844](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725105848844.png)
Base32的编码过程如下：

![image-20240725105916779](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725105916779.png)

Base32的解码过程为：首先查Base32编码的标准索引表，将信息转换为二进制数据。然后，根据等号数量确定丢弃比特的范围（即上表中的下划线部分），再按照8比特一组恢复出原始数据。在Koczkatamas工具包中，将Base32字符串复制到B32行，即可在第一行(ASCII)看到解码后的内容。Base32编码也可以实现信息隐藏，其原理和Base64编码的一样。这里我们直接提供其隐藏信息的结果。

Base64编码和Base32编码的比较如表

![image-20240725110017133](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725110017133.png)

## 4.Base16编码

Base16编码使用16个可见字符表示所有数据。其编码原理是把原始数据每个字节分为一组，将每组的8比特数据切分为2个4比特数据，然后根据Base16标准索引表（如表1.1.4所示）将4比特数据转换为对应的字符，即每个字节可以转换为2个字符表示。

![image-20240725145049923](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725145049923.png)

可以发现，Base16编码本质上是输出每个字节的十六进制表示，这种编码经常用在MD5、SHA1、SHA256、SHA512、SHA3等哈希算法的输出结果中。例如，“21232f297a57a5a743894a0e4a801fc3”是一个字符串的MD5值，根据Base16编码的原理，2个字符表示一个字节，所以该MD5值共有16字节。标准Base16编码也称为HEX编码或者十六进制编码。

Base16的**解码方法**是：在Koczkatamas工具包中将字符串复制到HEX行，即可在第一行(ASCII)看到解码后的内容。如果需要将Base16解码成文件，可以使用CyberChef中的From Hex，再单击“Save output to file”按钮，即可保存为文件。

## 4.其他Base系列编码
所有Base编码产生的原因都是想把不可打印字符转换为可打印字符，区别在于转换时的方法和索引表略有不同。接下来将简单介绍Base58、Base62和Base85的编码原理，这些编码都可以在CyberChef工具包中实现解码
### 1).Base58编码
Base58是一种独特的编码方式。其编码原理是：Base58的标准索引表中去掉了容易产生歧义的字符，如0（零）和O（大写字母O）、I（大写的字母I）和l（小写的字母L），以及影响双击选择的字符，如/和+。所以，Base58的标准索引表中正好有58个字符（包括9个数字、24个大写字母、25个小写字母），又因为58不是2的整次幂，因此没有采用Base64编码中的方法进行转换，而是采用辗转相除法实现原始数据和索引表中地址的转换，本质是转换为五十八进制。
### 2).Base62编码
假设我们现在是一位网页开发者，开发需求是在URL中传输数据，需要把不可打印字符转换为可打印字符再传输。我们马上想到采用Base64编码，但是Base64标准索引表中的“+”和“/”在URL地址中有特殊的含义（在URL中，“+”表示空格，“/”表示分隔目录和子目录）。此时有两种解决方案：
	①替换“+”和“/”，例如，对于commons-codec中的Base64.encodeBase64URLSafeString()，用“-”和“_”分别替换“+”和“/”；
	②采用一种新的编码传输，也就是Base62编码。
目前，各社交网站的短URL地址基本上都采用这种编码。其编码原理是：Base62的标准索引表有62个字符，顺序为：数字0～9、大写字母A～Z、小写字母a～z，这种编码也是采用辗转相除法实现原始数据和索引表地址的转换，其本质是转为六十二进制。
### 3).Base85编码
Base85是在Base64的基础上进一步压缩数据。Base85主要应用在PDF文档以及Git使用的二进制文件的补丁中。其编码原理为：用5个字符来表示4个字节。Base85还可以细分为标准型、ZeroMQ(Z85)和RFC1924三种
#### a.标准型
标准型也被称为Standard或者ASCII85，其索引表的字符集为ASCII码的“!”到“u”，共85个字符，用“z”表示0x00000000，“y”表示0x20202020。下面给出一个例子。
![image-20240725145545249](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725145545249.png)
#### b.ZeroMQ(Z85)
Z85是现有的ASCII85编码机制的一个派生版本，具有更好的可用性，特别适合在源代码中使用(https://rfc.zeromq.org/spec/32/)。
其索引表如下：
![image-20240725145532621](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725145532621.png)
##### c.RFC1924
RFC1924是针对IPv6地址的一种编码方式。原始IPv6地址需要32字节表示，经过这种方式编码，仅用20字节就可以表示一个IPv6地址(https://tools.ietf.org/html/rfc1924)。
其索引表如下：
![image-20240725145642817](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725145642817.png)
这三种格式都可以在开头和结尾添加“<～”和“～>”符号，并且在CyberChef工具包中可以手动选择不同格式后再进行解码。
#### d.解题技巧
如果遇到像Base64编码的字符串（特点是有大写字母、小写字母以及数字），但是经Base64解码后不是明文，那么可以在CyberChef工具包中用Base62、Base85、Base58等解码工具都尝试一遍。
## 5.Shellcode编码
Shellcode是一段利用软件漏洞而执行的代码，本质是十六进制的机器码，因攻击者可以通过其获得系统shell而得名。针对字符串，也可以采用Shellcode编码，其格式是在每个字符ASCII码的十六进制表示前加“\x”。
Shellcode编码后的字符串特征是每个字节前面都有“\x”。Shellcode编码的解码方法和Base16编码完全相同，在Koczkatamas工具包中直接把字符串复制到HEX行，不必删除“\x”，即可在第一行(ASCII)看到解码后的内容。
下面看一个例子。
```
编码前：
The quick brown fox jumps over the lazy dog
编码后：\x54\x68\x65\x20\x71\x75\x69\x63\x6b\x20\x62\x72\x6f\x77\x6e\x20\x66\x6f\x78\x20\x6a\x75\x6d\x70\x73\x20\x6f\x76\x65\x72\x20\x74\x68\x65\x20\x6c\x61\x7a\x79\x20\x64\x6f\x67
```
## 6.Quoted-printable编码
Quoted-printable表示“可打印字符引用”，该编码常用在电子邮件中，如Content-Transfer-Encoding:quoted-printable，它是多用途互联网邮件扩展(Multipurpose Internet Mail Extensions,MIME)的常见一种表示方法。其编码原理为：任何一个字节都可编码为3个字符：等号后跟随两个十六进制数表示该字节的数值。例如，ASCII码换页符（十六进制值为0x0C）可以表示为“=0C”，等号本身（十六进制值为0x3D）可以表示为“=3D”。
**除了可打印ASCII字符与换行符以外，所有字符必须表示为这种格式**。这意味着一般CTF比赛中的flag不会采用Quoted-printable编码，因为flag一般为字母和数字，采用这种编码后和原字符串相比没有任何变化。但是，在邮件取证或者邮件流量分析的题目中，会看到这种编码。Quoted-printable编码**最显著的特征是每个字节前面都有“=”**，利用在线网页http://web.chacuo.net/charsetquotedprintable和 CyberChef可以实现编码和解码功能。
下面给出一个在Unicode字符集下的例子
```
编码前：
敏捷的棕色狐狸跳过了懒惰的狗
编码后：=E6=95=8F=E6=8D=B7=E7=9A=84=E6=A3=95=E8=89=B2=E7=8B=90=E7=8B=B8=E8=B7=B3=E8=BF=87=E4=BA=86=E6=87=92=E6=83=B0=E7=9A=84=E7=8B=97
```
## 7.UUencode编码
UUencode是“UNIX-to-UNIX encoding”的简称，是在UNIX系统下将二进制数据通过UUCP邮件系统传输的一种编码方式，常用于电子邮件中的档案传送以及Usenet新闻组和BBS的帖文，等等。近年来已逐渐被MIME取代。UUencode的编码原理为：将输入数据按每3字节为一个单位进行编码，如果最后剩下的数据少于3字节，则用零补齐到3字节。3字节共有24比特，以6比特为单位分为4个组，每组数值在十进制下的范围是0～63，将每个数加上32，产生的结果刚好落在ASCII字符集中可打印字符(32～95)的范围内。输出时，每60个字符为独立的一行，每行的开头会加上长度字符。除了最后一行之外，长度字符都应该是“M”(32+45=77)，最后一行的长度字符为32+剩下的字节数目对应的ASCII字符。如果一个6比特组转换后为0，那么会被转换为0x60而不是0x20。下面给出一个例子。编码前：The quick brown fox jumps over the lazy dog
编码后：M5&AE（'%U:6-K(&)R;W=N（&9O>"!J=6UP<R!O=F5R（'1H92!L87IY（&1O9P"UUencode编码后的字符串的特征是：所有字符看起来像乱码，但都是可打印字符；如果有多行，那么除了最后一行，都以“M”开头。UUencode可以使用在线工具http://web.chacuo.net/charsetuuencode实现解码。
## 8.XXencode编码
Xencode的编码原理和Base64完全相同，只是转换时的索引表不同，可以看作变形的Base64。
![image-20240725150131948](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725150131948.png)
XXencode编码输出时的格式和UUencode相似，每60个字符为独立的一行，每行的开头会加上长度字符，除了最后一行之外，长度字符都应该是“h”（索引表中第45位），最后一行的长度字符为字节数在索引表中位置所代表字符。编码时默认填充比特0，填充的字符和具体的工具有关，在线XXencode解码网站http://web.chacuo.net/charsetxxencode用索引表的第一个字符作为填充。
下面给出一个例子。
```
编码前：
The quick brown fox jumps over the lazy dog
编码后：
hJ4VZ653pOKBf647mPrRi64NjS0-eRKpkQm-jRaJm65FcNG-gMLdt64FjNk++
```
## 9.URL编码
URL编码也称为百分号编码。URL地址规定，常用数字、字母可以直接使用，特殊用户字符（/,:@等）也可以直接使用，剩下的字符必须通过%xx编码处理。其编码方法很简单，就是在每个字节ASCII码的十六进制字符前面加“%”，如字符空格编码后的结果是%20。具体解码方法为：在Koczkatamas工具包中直接把字符串复制到URL行，即可在第一行(ASCII)看到解码后的内容。
## 10.摩斯码
摩斯码一般是指莫尔斯电码，也称作摩斯密码，它是由美国人萨缪尔·莫尔斯在1837年发明的。摩斯码是由点(.)和划(-)这两种符号组成的信号代码，通过不同的排列顺序来表达不同的英文字母、数字和标点符号。其中，点作为一个基本的信号单位，划的长度相当于3个点的时间长度；在一个字母或数字之内，每个点、划之间的间隔应该是两个点的时间长度；字母（数字）与字母（数字）之间的间隔是7个点的时间长度。摩斯码主要由以下5种代码组成：
```
点(.)
划(-)
每个字符间短的停顿（通常用空格表示停顿）
每个词之间中等的停顿（通常用“/”划分）
句子之间长的停顿。
```

| **字符** | **电码符号** | **字符** | **电码符号** |
| -------- | ------------ | -------- | ------------ |
| A        | ．━          | B        | ━ ．．．     |
| C | ━ ．━ ． | D | ━ ．． |
| E        | ．           | F        | ．．━ ．     |
| G | ━ ━ ． | H | ．．．． |
| I        | ．．         | J        | ．━ ━ ━      |
| K | ━ ．━ | L | ．━ ．． |
| M        | ━ ━          | N        | ━ ．         |
| O | ━ ━ ━ | P | ．━ ━ ． |
| Q        | ━ ━ ．━      | R        | ．━ ．       |
| S | ．．． | T | ━ |
| U        | ．．━        | V        | ．．．━      |
| W | ．━ ━ | X | ━ ．．━ |
| Y        | ━ ．━ ━      | Z        | ━ ━ ．．     |
| 0 | ━ ━ ━ ━ ━ | 1 | ．━ ━ ━ ━ |
| 2        | ．．━ ━ ━    | 3        | ．．．━ ━    |
| 4 | ．．．．━ | 5 | ．．．．． |
| 6        | ━ ．．．．   | 7        | ━ ━ ．．．   |
| 8 | ━ ━ ━ ．． | 9 | ━ ━ ━ ━ ． |
| .        | ．━ ．━ ．━  | :        | ━ ━ ━ ．．． |
| , | ━ ━ ．．━ ━ | ; | ━ ．━ ．━ ． |
| ?        | ．．━ ━ ．． | =        | ━ ．．．━    |
| ' | ．━ ━ ━ ━ ． | / | ━ ．．━ ． |
| !        | ━ ．━ ．━ ━  | ━        | ━ ．．．．━  |
| _ | ．．━ ━ ．━ | " | ．━ ．．━ ． |
| (        | ━ ．━ ━ ．   | )        | ━ ．━ ━ ．━  |
| $ | ．．．━ ．．━ | & | ． ．．． |
| @        | ．━ ━ ．━ ． |          |              |

## 11.JSFuck编码
JSFuck是一种人类难以阅读的基于JavaScript的编程语言，代码中仅使
```
[	]
(	)
!	+
```
理论上，JSFuck的运行不需要依赖浏览器，它也可以在Node.JS上运行。具体的转换原理可以参考官方网站http://www.jsfuck.com。
注意，JSFuck代码和JavaScript代码不是一一对应的关系。一般而言，规范书写的JavaScript代码都能转换成JSFuck代码，但JSFuck代码不一定都能转换成JavaScript代码。在CTF比赛中，JSFuck常用于JavaScript的加密，需要选手运行JSFuck代码或者手工解密，读懂代码内部逻辑。
JSFuck的运行方法如下：打开浏览器，按<F12>键打开调试界面，选择控制台(Console)选项卡，复制代码，按回车键即可显示运行结果。如果浏览器运行报错，可以检查字符串是否复制完整或者换用QQ、360等浏览器。
## 12.Brainfuck编码
Brainfuck是一种极小化的**程序语言**，本质上它并不属于编码。它是由Urban Muller于1993年创造的，发明Brainfuck是为了创建一种简单的、可以用最小的编译器来实现的、符合图灵完备思想的编程语言。这也导致Brainfuck代码对非专业人员基本不可读。该语言只有八种符号，所有操作都由这八种符号的组合来完成

| 字符 | 含义                                                         |
| ---- | ------------------------------------------------------------ |
| >    | 指针加一                                                     |
| <    | 指针减一                                                     |
| +    | 指针指向的字节的值加一                                       |
| -    | 指针指向的字节的值减一                                       |
| .    | 输出指针指向的单元内容(ASCII码)                              |
| ,    | 输人内容到指针指向的单元(ASCII码)                            |
| [    | 如果指针指向的单元值为零，向后跳转到对应的】指令的下一指令处 |
| ]    | 如果指针指向的单元值不为零，向前跳转到对应的「指令的下一指令处 |

Brainfuck代码可利用在线工具https://www.splitbrain.org/services/ook实现编码和解码。

![image-20240725153831939](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725153831939.png)

所示是字符串“Hello world”对应的结果。

如果输出结果较为规范，则应该是5个字符为一组，每组以空格分隔，代码开头部分有若干加号，这些可以作为识别Brainfuck代码的明显特征。Brainfuck代码还有变形，分别是Ook！和Short Ook！代码。

Ook！是一种由David Morgan-Mar创建的编程语言，它与Brainfuck完全相同，只是指令被改成了其他表示形式。Ook！只包含3种符号：Ook.，Ook！和Ook?，见表1.1.7，这也导致Ook！编码的特征过于明显。

![image-20240725153904004](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725153904004.png)

例如，例题ook_example.txt的Ook编码为

![image-20240725154006871](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725154006871.png)

在https://www.splitbrain.org/services/ook中选择Ook! To Text，得到结果Ook。为了缩短书写时间和避免多次编码，有时会通过删除Ook简化代码，使其成为三元代码，即只有3种符号——点(.)、问号(?)和感叹号(!)，

Short Ook！与Brainfuck的对应关系

![image-20240725154055561](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725154055561.png)

“Hello world”对应的规范化的Short Ook！如下：

![image-20240725154116293](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725154116293.png)

[][插图]其特点也是5个字符为一组，每组以空格分隔，开头有若干个点(.)

###### 可以使用离线工具https://github.com/jcharra/ook/blob/master/ook.py运行Brainfuck、Ook！和Short Ook！代码，得到运行结果。使用方法为：运行命令python2ook.py -o/-b xxx.txt，其中-o是对Ook！和Short Ook！解码，-b是对Brainfuck解码。

# 二.网络流量分析

网络流量分析是指利用分析技术和统计手段对网络数据包进行处理，从而实现对网络的行为分析、性能分析和故障诊断等。它也是网络取证中经常使用的手段。

## 1.基础知识

网络协议是为在网络中进行数据交换而建立的规则、标准或约定的集合，通常也简称为协议。互联网的核心是一系列协议，总称为互联网协议(Internet Protocol Suite)，它们对计算机如何连接和组网做出了详尽的规定，一个协议通常只为一个目的而设计。那么应该如何设计网络协议呢？

ARPANET（阿帕网）是美国国防高级研究计划局开发的世界上第一个运营的数据包交换网络，是全球互联网的鼻祖。但是，ARPANET无法和使用不同操作系统的计算机进行网络交流，这引发了研究者的思考。ARPANET的研制经验表明，对于非常复杂的网络协议，其结构应该是层次式的。1984年，国际标准化组织(International Organization for Standardization, ISO)发布了ISO/IEC 7498标准，它定义了网络互连的7层框架，也就是开放式系统互连参考模型(Open System Interconnection Reference Model, OSI/RM)

​					 OSI/RM体系

| 层次           | 说明                                                       |
| -------------- | ---------------------------------------------------------- |
| 应用层         | OSI体系结构中的最高层，是网络服务与最终用户的一个接口      |
| 表示层         | 实现数据的表示、压缩和安全性                               |
| 会话层         | 建立、管理、终止会话                                       |
| 传输层(运输层) | 定义传输数据的协议端口号，以及流量控制和差错校验等         |
| 网络层(网际层) | 进行逻辑地址寻址，实现不同网络之间的路径选择               |
| 数据链路层     | 实现建立逻辑链路、物理地址寻址、差错校验等功能             |
| 物理层         | 利用传输介质为数据链路层提供物理连接，实现比特流的透明传输 |

OSI期望达到一种理想境界，即全球网络都遵循这个统一的标准，因此在标准制定的过程中试图涵盖当时最先进的技术，导致制定周期漫长。当OSI标准还在讨论时，一种新的网络协议在工业界被广泛采纳，而且被众多厂商使用，这就是TCP/IP。于是，OSI面临着非常尴尬的局面：大公司和厂商都认可OSI，但几乎找不到厂商能生产出符合OSI标准的商用产品；而基于TCP/IP的互联网已抢先在全球大范围运行，成为事实上的国际标准。

传输控制协议/网际协议(Transmission Control Protocol/Internet Protocol, TCP/IP)包含**应用层、传输层（也称为运输层）、网络层（也称为网际层）和网络接口层**。但在学习计算机网络原理时，往往采取折中的方法，综合OSI和TCP/IP的优点，采用一个五层协议的体系结构，这样的体系结构称为协议栈。

![image-20240725154730553](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725154730553.png)

​						常见网络协议

| 层次       | 协议                                         |
| ---------- | -------------------------------------------- |
| 应用层     | HTTP、FTP、DNS、Telnet、HTTPS、POP3、DHCP 等 |
| 传输层     | TCP、UDP 等                                  |
| 网络层     | ICMP、IGMP和IP(IP4、IPv6)等                  |
| 数据链路层 | Ethernet、IEEE802.3、PPP和HDLC等             |

有了协议栈的概念，我们就可以描述主机之间是如何通信的，如图所示。

主机A、B、C均有自己的网络协议栈，A向B发起请求，需要使用协议栈中各层提供的服务。图中的客户端程序和服务端程序都可以看作进程，若仅考虑进程之间的交互，则可以看作虚线表示的连接。对于相应的协议，我们可以按照下面的描述简单理解，网络层的IP协议头部会保存要连接的主机的IP地址，传输层的TCP或UDP的头部会保存端口信息，IP地址可以确定连接的主机，但不能确定是哪个进程，端口信息可以确定和哪个进程完成信息交互。

​						通信过程

![image-20240725155004368](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725155004368.png)

## 2.Wireshark的基本使用方法

当前，网络分析工具种类众多，常用的工具有Wireshark、CommView、Fiddler等，本节重点介绍Wireshark的使用方法。Wireshark是目前广泛应用的网络协议分析器，大部分企业、政府机构和教育机构都使用它作为网络分析工具。Wireshark的前身是1998年由Gerald Combs开发的Ethereal，出于一些商业原因，2006年起使用Wireshark这个名字。

在使用过程中，Wireshark更像一个“观测者”，把所有网络数据包忠实地捕获并展现出来。使用Wireshark的优势在于：安装方便，支持跨平台；图形化操作界面简单易用，操作友好，能提供多种辅助分析功能。但是，Wireshark并不是万能的，其缺点十分明显，例如，不能处理网络事务，只能“测量”（监视）网络；不能发送网络包或完成网络交互；不能作为入侵检测软件发现网络异常流量；不能修改网络数据包（也叫网络封包）的内容。

Wireshark有两大功能。第一个功能是对指定网卡实现“抓包”（正式的说法为“数据包捕获”），即捕获从网卡发送或者接收的每一个数据包，从而实时分析网络流量。直接打开Wireshark，可以看到网卡选择界面。第二个功能是可以打开保存好的网络数据包，离线分析网络流量，这也是目前CTF比赛中常见的题目类型。Wireshark安装完成后，会关联pcap、pcapng等后缀的文件，双击打开这些文件，就可以在Wireshark中看到离线网络流量了。

打开pcap离线文件，Wireshark的主界面如图所示。本节演示所使用的Wireshark版本为3.4.0，建议读者实践时下载最新版。“数据包窗口”显示每个单独的数据包，默认按照时间顺序显示。“TCP/IP协议栈解析窗口”用TCP/IP协议栈解析在“数据包窗口”选中的数据包。**第一行**“Frame”显示第几个数据包，以及数据包总长度等信息；从**第二行**开始，按照对应的协议逐层解析。例如，第1个数据包是TCP三次握手的第一个包，所以只解析到传输层的TCP，每层协议都可以通过单击三角符号显示更详细的解析结果。“数据显示窗口”以十六进制的形式对所有数据逐字节显示，其中很多数据都是不可打印字符。在“TCP/IP协议栈解析窗口”选择不同的字段，“数据显示窗口”中的相应数据会变为蓝色背景。

![image-20240725155206846](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725155206846.png)

###### a.显示过滤器的使用

```
方法一：利用Wireshark自带的表达式生成器。单击“分析”按钮后选择“Display Filter Expression”，打开表达式生成器，见图1.2.7。打开后的界面如图1.2.8所示，“字段名称”是各个协议，展开后可以看到具体的协议字段；“关系”是指对选中字段的具体逻辑要求。图中的过滤规则为“http.request.method=="GET"”，即把HTTP的GET请求包都过滤出来。如果表达式正确的话，背景会变为绿色。[插图]图1.2.7 如何打开表达式生成器，过滤表达式当对过滤规则不熟悉时，可以采用这种方法，但是通过表达式生成器只能生成一条规则，不能实现多个规则的并列。

方法二：利用显示过滤器的规则补全功能。直接在显示过滤器中输入过滤规则，大部分协议名的小写都可以直接作为过滤规则使用，例如，输入“http”，就可以把所有包含HTTP协议的数据包过滤出来。在协议名后面输入点(.)，显示过滤器会把相关字段自动显示出来。如图1.2.9所示，输入“req”，会把请求相关的字段自动显示出来，这样有助于快速补全表达式。这种方法的优点在于可以任意建立规则，缺点是如果对规则不熟悉，就需要花大量时间完善表达式，建议各位读者熟练掌握一些常用的过滤规则的用法
```

**注意**：多个表达式并列时，可以用“&&”或者“||”。“&&”代表“与”，表示需要同时满足多个规则；“||”代表“或”，表示多个规则中有一个被满足，表达式即可成立

###### b.统计功能

```
Wireshark的工具栏中自带统计功能，这些功能对流量分析具有关键作用，可以快速实现对当前离线数据包中的协议类型统计、数据包过滤、流量统计和HTTP请求提取等功能

(1)协议分级统计
协议分级统计是对显示过滤器中过滤出的数据包，按TCP/IP协议栈从底层向高层逐层进行统计，显示每个协议的数据包数、字节数以及各协议所占的百分比。如果一个数据包解析后最高层协议是TCP，那么该数据包的字节数等信息会被统计到Frame、Ethernet、IPv4和TCP四个层次中。“结束分组”和“结束字节”分别指该协议作为最高层协议时的包数和字节数，可以理解为以该协议作为数据包解析的结束。

统计功能协议分级统计是流量分析中最常使用的工具，通过这个工具可以直观、全面地了解当前所有数据包的流量，包括存在哪些协议以及各协议的占比。
对于想要过滤出来的协议，可以单击鼠标左键选中协议名称，再单击鼠标右键选择“作为过滤器应用”，然后选择“选中”，就可以把该协议对应的数据包全部过滤出来，显示过滤器也会随之变化

(2)端点统计
端点是指网络上能够发送或者接收数据的一台设备。
Wireshark的端点统计可以理解为根据Ethernet、IP、TCP或UDP，统计各地址接收或者发送的数据量。可以选择不同的协议层级，
	Ethernet对应MAC地址，IP只有IP地址，
	TCP和UDP中包含IP地址和端口信息
```

​						端点统计中各字段的含义

| 字段       | 说明                     |
| ---------- | ------------------------ |
| Address    | 端点地址                 |
| Port       | 端点端口                 |
| Packets    | 包含该地址的数据包数     |
| Bytes      | 包含该地址的数据包字节数 |
| Tx Packets | 发送的数据包数           |
| Tx Bytes   | 发送的字节数             |
| Rx Packets | 接收的数据包数           |
| Rx Bytes   | 接收的字节数             |

```

(3)会话统计
会话统计功能可以统计两个端点之间发送/接收数据包的数量、字节大小以及数据的流向情况，也可以通过排序来判断占用最大带宽的主机，

(4)HTTP统计
HTTP统计包括四个功能，分别是
	分组计数器、请求
	负载分配、请求序列
“分组计数器”包含HTTP请求类型和响应代码的统计信息。“请求”是经常用到的一个重要功能，包含主机(host)和URI的完整信息。“负载分配”会展示基于服务器地址和主机的HTTP请求和响应统计信息，从而了解数据包在各网站的分布情况。“请求序列”是Wireshark2.6之后版本新增的的功能，使用HTTP的Referer和Location头将捕获的HTTP请求作为树进行展示，分析人员就能够看到一个HTTP请求如何导向下一个HTTP请求。
```

###### c.追踪流

```
流通常指一个由源IP地址、源端口、目的IP地址、目的端口、应用协议组成的五元组。
这个概念在流量分析中经常被使用。Wireshark的追踪流功能其实是根据{IP A, port A, IP B, port B}这四个元素进行划分，针对某一协议（如TCP），将五元组[IP A, port A,IP B, port B, TCP]和[IP B, port B, IP A, port A,TCP]的信息映射到一个流中，从而实现追踪某条TCP流完整会话的功能。

追踪流的具体方法为：在数据包窗口选中数据包，单击鼠标右键，即可看到追踪流选项，如图1.2.16所示。可以根据要分析的协议，选择追踪TCP流、UDP流或者HTTP流等。如果是分析HTTP，建议选择追踪HTTP流，这是因为服务器返回包会采用gzip压缩数据，如果对HTTP的数据包选择追踪TCP流，那么看到的是压缩后传输的数据内容；如果选择追踪HTTP流，就可以看到解压后的数据内容

我们可以利用一个技巧来简单、方便地查看到每一条TCP连接流的内容。对任意TCP数据包，选择“追踪TCP流”，可以看到追踪得到的信息，显示过滤器的过滤规则也会发生变化。例如，对于“tcp.stream eq 13”，通过修改数字，可以从0开始查看到每一条TCP流的信息。对于过滤出来的任意一个数据包，再选择“追踪TCP流”，就能看到Wireshark整理后的完整会话结果。
```

###### d.提取文件或数据

```
当我们千辛万苦地找到了关键协议后，下一个考查重点就是如何从中提取重要的文件或者数据。我们以HTTP协议为例，介绍三种文件提取方法。首先简单介绍下HTTP中的GET和POST请求方法，GET方法是客户端向服务器请求资源（文本、图像、音视频等），服务器把相应的资源返回给客户端；POST方法是向服务器提交数据处理请求（例如提交表单或者上传文件），数据被包含在请求体中。针对GET方法，要提取的文件或数据应该在服务器的返回包中；而对于POST方法，要提取的关键文件或数据在客户端的请求包中，这个细节上的区别需要读者们重点掌握。

								方法一：导出对象法
这种方法依赖于Wireshark自带的解析功能，设备之间通过网络传输的文件在Wireshark中被称为“对象”。单击“文件”工具栏，可以找到“导出对象”选项，Wireshark可以根据不同的协议自动导出文件。单击“save”按钮，即可导出zip压缩包。用这种方法导出时，文件名由Wireshark根据流量自动生成。
这是一种“傻瓜式”方法，是三种方法中操作最为简单的一种，理论上可以把某个协议传输的文件全部导出。但是，当离线流量太大或者传输文件头部受损时，这种方法会失效。而且，导出对象法目前仅支持5种协议，应用范围十分有限，对于大量通过其他协议传输的文件，只能采用人工提取方式。

								对象方法二：导出分组字节流法
这是一种完全由人工操作的提取方法，具有广泛的适用性，需要读者们熟练掌握。根据上面的分析，压缩包在服务器的返回包中。在“数据包窗口”单击第二个HTTP包，可以查看协议解析结果，如图1.2.20所示。在HTTP协议下面有Media Type层，这个就是服务器返回的文件。将树状解析结果展开，可以看到“application/zip”，说明文件是zip格式，共197个字节。单击鼠标左键选中“application/zip”行，再单击鼠标右键，选择“导出分组字节流”。导出的文件需要手动命名，默认是*.bin文件，这要求我们对文件格式以及流量的交互信息非常熟悉。


								方法三：binwalk提取法
利用binwalk对离线流量文件进行检测和提取的方法在杂项题目中有一定的普适性。事实上，几乎所有杂项题目都可以用binwalk检测。用binwalk对pcap文件检测后，再添加“-e”选项，就可以提取出对应的文件。当离线流量较小时，这种方法比较有效，并且不用考虑协议的细节。但是，当流量较大时，提取出的文件太多，会影响进一步分析。binwalk检测的原理是根据文件头特征，如果流量中文件的文件头损坏，binwalk也无法提取成功，这时仍需要手工提取。
```
###### e.导出特定数据包
```
CTF比赛中拿到的离线流量往往有很多杂包，如果文件大小达到上百兆，那么打开文件和过滤数据包会占用较长时间。此时，可以把某种协议的数据包单独过滤出来再保存。以过滤HTTP数据包为例，具体方法为在“显示过滤器”中输入“http”，单击回车键使过滤条件生效。单击“文件”，选择“导出特定分组”，即可把过滤出的数据包保存成一个新的离线文件，方便后续做进一步分析。需要特别说明的是，在过滤出HTTP数据包后，在“文件”中选择“另存为”是没有用的。
```
## 3.CTF流量分析的通用方法
​								流量分析的通用方法

![image-20240725190100337](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725190100337.png)

打开离线流量文件后，可以先观察一下分组数。如果分组数小于1000个，可以手工逐个数据包查看。因为当数据包个数较少时，协议分级的效果并不明显。而且，如果题目的分组数较少说明考点较为直接，杂包过滤可能并不是重点。

如果分组数较多，通过**协议分级**可以看到各协议所占的比例。如果流量中存在Telnet、FTP、ICMP等明文传输协议，建议通过追踪流或过滤的方法，优先查看这些协议的通信过程。

如果没有上述协议，而是存在大量的HTTP（所谓“大量”，一般是指字节数占比较大），那么HTTP就是接下来分析的重点。通过“**统计-HTTP-请求**”工具，可以查看所有URL的详细信息。对于一般的Web流量，通过URL就可以看到所有请求的资源。如果是SQL注入攻击流量，在URL中会有大量的SQL特征。如果是菜刀、蚁剑等工具生成的流量，会存在大量的POST包，通过逐个查看POST请求的返回包，也可以掌握通信过程。

如果离线文件中均无上述协议，就需要结合题目的描述进行针对性分析。例如，若题目中存在大量DNS协议，就需要重点关注查询的域名以及对该域名的响应。假如存在USB协议，则需要结合协议载荷判断设备类型，再根据设备通信规则复原出传输的信息。
## 4.ICMP
ICMP(Internet Control Message Protocol)也称为Internet控制报文协议，它允许主机或路由器报告差错情况，并提供有关异常的报告。这些控制消息虽然不传输用户数据，但是对于用户数据的传递起着重要作用。需要注意的是：ICMP并不是高层协议，它和IP同属于网络层，但是对于用户数据的传递起着重要作用。需要注意的是：ICMP并不是高层协议，它和IP同属于网络层，但是ICMP报文封装到IP数据报中。ICMP报文如图1.2.25所示，它的报文头部为8字节，定义如下：

```C
typedef structicmphdr {
    unsigned char i_type ;     //8比特，类型
    unsigned char i_code;     //8比特，代码
    unsigned short i_cksum;    //16 比特，被验和
    unsigned short i_id;	//标识符(-般用进程号作为标识符)，用于匹配ECHO和ECHO REPLY包
    unsigned short i_seg;		//报文序列号，用于标记ECHO报文顺序
    unsigned int timestamp;		// 时间戮或未使用
}ICMP HEADER;
```

​							ICMP报文

![image-20240725190728109](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725190728109.png)

ICMP的一个重要应用是分组网间探测(Packet InterNet Groper, PING)，它可以用于测试两个主机之间的连通性。PING使用了ICMP回送(echo)请求与回送回答报文。ICMP echo报文如下所示。

![image-20240725190754515](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725190754515.png)

不难发现，数据部分可以用来传输消息。不同操作系统的数据部分的填充方法略有区别：在Windows系统下采用小写字母a～w循环；在Linux系统下，使用“-p”选项可以指定发送的数据，默认是0x00～0xFF的循环。

此时，读者们应该能想到ICMP的一种出题方法，就是在数据部分隐藏flag，将flag编码或者加密后经ICMP请求包传输。这个考点较为简单，在发现ICMP数据部分异常后，就转化为上节介绍的常见编码的问题。

数据部分明文传输的相关题目比较简单，为了增加比赛难度，一些出题人会想出新的考点。ICMP的另一个考点是以数据部分的长度表示要传输的信息，其本质是基于文本的信息隐藏。

## 5.Telnet

Telnet是Internet远程登录服务的标准协议和主要方式，为用户提供了在本地计算机上远程管理主机的能力。实际上，Telnet的出现早于TCP/IP协议簇的其他应用层协议。它默认TCP端口号为23。Telnet的一个特点是以明文方式传输所有数据，这也意味着如果捕获了Telnet网络流量，就可能找到远程登录的用户名和密码。作为一种不安全的远程登录协议，Telnet几乎被SSH协议所替代，只有在某些场景下才会使用Telnet远程登录。

Telnet有四种**工作模式**，这里重点介绍两种。第一种是一次一字符模式，当用户输入命令时，**每按一个键，Telnet客户端会立刻把该字符发送给远程服务器**，然后从TCP连接上读取收到的字符，返回给Telnet客户端，显示给用户看。大部分Telnet默认采用这种工作模式。第二种是准行模式(kludge line mode)，用户每键入一行信息，客户端向服务器发送一次信息。Telnet的考点主要是获取用户登录时的正确密码，通常采用一次一字符模式进行传输。

## 6.FTP

FTP（File Transfer Protocol，文件传输协议）是TCP/IP协议簇中的应用层协议之一。FTP服务包括FTP服务器和客户端，其中FTP服务器用来存储文件，用户可以使用FTP客户端通过FTP访问位于FTP服务器上的资源。在开发网站的时候，通常利用FTP把网页或程序传到Web服务器上。此外，由于FTP传输效率非常高，因此在网络上传输大的文件时，一般也采用该协议。

默认情况下，FTP使用TCP端口中的20和21这两个端口，其中20用于传输数据，21用于传输控制信息。但是，是否使用20作为传输数据的端口与FTP使用的传输模式有关，如果采用主动模式，那么数据传输端口就是20；如果采用被动模式，则最终使用哪个端口要由服务器端和客户端协商决定。

FTP命令由3～4个字母组成，命令后面跟参数，用空格分开。每个命令都以“\r\n”结束。常用的FTP命令有USER、PASS、SIZE、REST、CWD、RETR、PASV、PORT、QUIT等。各命令含义如下：

```
USER：指定用户名。通常是控制连接后第一个发出的命令。“USER name\r\n”表示以用户名name登录。

PASS：指定用户密码。该命令紧跟在USER命令后。“PASS 123456\r\n”表示密码为123456。

SIZE：从服务器上返回指定文件的大小。“SIZE file.txt\r\n”表示如果file.txt文件存在，则返回该文件的大小。

CWD：改变工作目录，如“CWD dirname\r\n”。❑PASV：让服务器在数据端口监听，进入被动模式，如“PASV\r\n”。

PORT：告诉FTP服务器客户端监听的端口号，让服务器采用主动模式连接客户端，如“PORT h1,h2,h3,h4,p1,p2”。

RETR：下载文件。“RETR file.txt\r\n”表示下载文件file.txt。

STOR：上传文件。“STOR file.txt\r\n”表示上传文件file.txt。

REST：该命令并不传送文件，而是忽略指定点后的数据。此命令后应该跟其他要求文件传输的FTP命令。比如，“REST 100\r\n”表示重新指定文件传送的偏移量为100字节。

QUIT：关闭与服务器的连接。
```

## 7.DNS

TCP/IP协议簇中使用IP地址和端口号来确定网络上某一台主机中的某一个服务，那么为什么不用域名来直接进行通信呢？因为IP地址的长度是固定的，而域名的长度是可变的，可变的域名不便于计算机处理，而IP地址对于用户来说不方便记忆，但域名便于用户使用。总结来说就是：IP地址是面向主机的，而域名是面向用户的。

DNS(Domain Name System)也称为域名系统，是将域名和IP地址相互映射的一个分布式数据库，能够让用户更方便地访问互联网。DNS协议运行在UDP/TCP之上，默认端口号是53 ，query表示查询，query response是对查询的响应；0xf4d7是会话标识，因为大部分DNS报文是基于UDP的，通过会话标识可以区分DNS应答报文是对哪个请求的响应。

## 8.HTTP

HTTP是Hyper Text Transfer Protocol（超文本传输协议）的缩写，目前通过浏览器访问页面几乎都是基于HTTP完成的。该协议默认占用TCP的80端口。在CTF比赛中，HTTP非常常见。由于HTTP的细节十分繁杂，本节只介绍最基础的内容。首先介绍HTTP请求格式，如图1.2.32所示，HTTP请求包含头部(header)和实体（body，也称为主体），头部的第一行包括方法、URI和协议版本，以空格分隔；头部中还有其他字段，每个字段占一行，例如，Host说明访问网站的域名或者IP地址，User-Agent说明用户使用的操作系统和浏览器等信息。头部字段是可以任意添加和修改的。头部的行之间以“\r\n”分隔，头部和实体之间用两个“\r\n”分隔。HTTP响应的格式和请求格式一致。

​								HTTP请求格式

![image-20240725191912157](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725191912157.png)

​								HTTP响应格式

![image-20240725191952363](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725191952363.png)

## 9.USB

USB(Universal Serial Bus)的全称是通用串口总线，USB流量指的是USB设备接口的流量，攻击者能够通过监听USB接口流量获取键盘敲击键、鼠标移动与点击、存储设备的明文传输通信、USB无线网卡网络传输内容等信息。在CTF比赛中，USB流量分析主要以键盘和鼠标流量为主。图1.2.41显示的是从本地机器捕获的USB接口流量，需要注意的是，USBPcap pseudoheader（伪头）不属于发送内容部分，而是USBPcap控制程序的部分，pseudoheader后面的部分才是真正要发送或接收到的内容。在这个例子中，URB就是pseudoheader，占27字节，真正发送的内容是Leftover Capture Data中的8字节。

![image-20240725192347883](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725192347883.png)

键盘和鼠标传输的内容就在Leftover Capture Data中。键盘数据包的数据长度为8字节，击键信息集中在第3个字节，这个字节并不是字符的ASCII码，具体映射关系需要查看USB HID USAGE TABLE第53页的内容。

鼠标移动时表现出连续性，但实际上鼠标动作所产生的数据包是离散的，每一个数据包的数据区有4个字节，第1个字节代表按键，值为0x00时，表示没有按键；值为0x01时，表示按左键；值为0x02时，表示当前按键为右键。第2个字节可以看成一个signed byte类型，其最高位为符号位，当这个值为正时，代表鼠标水平右移多少个像素；这个值为负时，代表鼠标水平左移多少个像素。第3个字节与第2个字节类似，代表鼠标垂直移动的像素数。得到这些信息后，即可恢复出鼠标移动轨迹。

针对键盘和鼠标的USB流量分析，可以使用开源工具https://github.com/WangYihang/UsbKeyboardDataHacker和https://github.com/WangYihang/UsbMiceDataHacker完成。这两个工具可以从流量包中读出击键内容并恢复出鼠标轨迹。

## 10.TLS

SL/TLS是一种密码通信框架，也是目前使用最广泛的密码通信方法。SSL/TLS综合运用了密码学中的对称密码、消息认证码、公钥密码、数字签名、伪随机数生成器等算法。SSL（Secure Socket Layer，安全套接层）是1994年由Netscape公司设计的一套协议，并于1995年发布了3.0版本。TLS（Transport Layer Security，安全传输层）是IETF在SSL 3.0基础上设计的协议，相当于SSL的后续版本。

TLS协议位于传输层和应用层之间，其功能是一个加密通道，和上层应用协议无关。由于HTTP采用明文传输，很容易被攻击者窃听或者篡改内容，通过引入TLS对HTTP的内容进行加密等操作，可以有效防止窃听、篡改和劫持等

​							TLS协议简介

![image-20240725192517332](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725192517332.png)

## 11.IEEE 802.11

WLAN（Wireless Local Area Network，无线局域网）是利用电磁波传送数据形成的无线网络。设备通过AP（Access Point，无线接入点）连接到WLAN，我们平时连接的热点就属于AP。WLAN有WAPI和Wi-Fi两种传输标准，其中，Wi-Fi（Wireless Fidelity，无线保真）属于短距离无线技术，也是平时我们使用最多的网络传输标准，其数据传输使用的是IEEE 802.11协议，该协议又细分为20多个子协议。

主要考查如何破解出连接热点时的密码。

我们连接热点时有多种加密类型:

```
1).WEP
(Wired Equivalent Privacy)的全称为有线等效保密，采用RC4 prng算法。客户端与无线接入点的数据都会以一个共享的密钥进行加密，密钥的长度有40位和256位两种，密钥越长，就需要更多的时间进行破解。此类加密方式比较老旧，只需要捕获大量的网络数据包就可破解。
```

```
2).WPA
(Wi-Fi Protected Access)是不安全的WEP标准的演变，采用128位密钥和48位初向量(IV)的RC4算法加密。WPA的主要改进是可以动态改变密钥的临时密钥完整性协议(Temporal Key Integrity Protocol, TKIP)。WPA是在802.11i完备之前替代WEP的过渡方案，WPA2才是最终的标准体系。WPA/WPA2是一种非常安全的加密类型，由于此加密类型需要安装Radius服务器，因此，普通用户一般用不到，只有企业用户为了无线加密更安全才会使用此种加密方式。在设备连接无线Wi-Fi时需要Radius服务器认证，而且需要输入Radius密码。
```

```
3).WPA-PSK/WPA2-PSK
是我们现在经常设置的加密类型。这种加密类型安全性高，设置简单。需要注意的是，它有AES和TKIP两种加密算法。这种加密类型仍然可以被破解，其破解方法是先捕获握手包，然后通过字典进行爆破。
```

**WPA-PSK的破解原理**

```
SSID（Service Set Identif ier，服务集标识符）：也可以写为ESSID，用来区分不同的网络，最多可以有32个字符，无线网卡设置了不同的SSID就可以进入不同网络。可以简单地理解为，连接的不同Wi-Fi的名字就是SSID。

口令：连接WiFi时需要输入的安全密钥。

PSK（Pre-Shared Key，预共享密钥）：口令经PSK映射转换算法处理后得到的结果。

MIC(Message Integrity Code)：消息验证码。

四次握手（重头戏来了！）：设备和AP为创建和分发动态加密密钥而相互发送4条信息，每条信息都包含一些重要内容，其中第3条信息包含一个重要的MIC，第4条信息包含一个报文信息。
```

```
破解步骤如下：
1)口令经一个算法计算得到PSK。
2)PSK+SSID生成PMK（PMK是什么不重要，这里我们把它记成“张三”）。
3)结合四次握手中前三次的信息以及张三(PMK)，计算得到PKT（记不住的话叫“李四”）。
4)结合李四和四次握手中第4条的报文计算出新MIC，新MIC和四次握手中第3条的MIC比较，如果一致，说明口令正确；如果不一致，就从字典中获取一个新口令，重复上述步骤。

在实际破解过程中，不清楚原理也没有任何影响，我们可以使用Kali自带的aircrack-ng工具破解流量中的Wi-Fi密码。在这个过程中需要使用字典，可以说，破解能否成功完全取决于字典的好坏。
```

# 三.日志分析

日志（也称为Log）是系统运行时所发生事件的相关记录，包括日期、时间、使用者及操作等信息的描述。日志分析就是对这些记录进行审查与评估，以发现系统中可能存在的风险。

## 1.Web日志及分析方法

Web日志是对网络流量某些关键信息的提取和记录，其本质是一种网络流量的变形。常见的Web日志主要基于Apache和IIS，每一类中又包含规范化格式类型和自定义格式类型。规范化的Web日志格式包括Apache的**NCSA日志格式**和IIS的**W3C日志格式**。其中，NCSA格式分为NCSA普通日志格式(CLF)和NCSA扩展日志格式(ECLF)两种。目前最常用的日志格式是NCSA扩展日志格式及基于自定义格式类型的Apache日志格式。W3C扩展日志格式(ExLF)具备更丰富的输出信息，但目前应用并不广泛。

下面是一个常见的基于NCSA扩展日志格式(ECLF)的Apache日志样例：

![image-20240725193323346](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725193323346.png)

含义：

```
❑第1项(58.61.164.141)是远程主机的IP地址。❑第2项(-)是空白，用一个“-”占位符替代。这个位置用于记录浏览者的标识，一般是浏览者的E-mail或其他唯一标识，因为涉及用户邮箱等隐私信息，目前几乎所有的浏览器都取消了这项功能。❑第3项(-)用于记录浏览者进行身份验证时提供的名字。如果需要身份验证，则这项不为空。但目前在大多数网站的日志中，这项依旧为空。❑第4项([22/Feb/2010:09:51:46+0800])是请求的时间，格式为[日期/月/年：小时：分：秒时区]。❑第5项(GET/reference-and-source/weblog-format/HTTP/1.1)记录了服务器收到的Web请求，格式为“请求方法请求资源协议版本”。❑第6项(206)是状态码，用于表示服务器的响应状态，通常1××的状态码表示继续消息；2××表示请求成功；3××表示请求的重定向；4××表示客户端错误；5××表示服务器错误。❑第7项(6326)表示发送给客户端的总字节数。把日志中的这个值加起来就可以得知服务器在一天、一周或者一月内发送了多少数据。
❑第8项(http://www.google.cn/search?q=webdataanalysis)用于表示浏览者在访问该页面之前所浏览的页面(Referrer)，只有从上一个页面链接过来的请求才会有该项输出，如果是新开的页面，则该项为空。上例中的来源页面是google，即用户从google搜索的结果中单击进入。❑第9项（Mozilla/4.0(compatible; MSIE 6.0;Windows NT 5.1)）是客户端的User-Agent信息，包括操作系统的内核版本以及浏览器版本等信息。下面是一段常见的IIS产生的W3C扩展Web日志，各字段也以空格分隔：
2011-09-01 16:02:22 GET /Enterprise/detail.asp 70.25.29.53 http:/kwww.example.
com/searchout.asp 20217735 3694656

各字段的含义分别为：日期(2011-09-01)，时间(16:02:22)，请求方法(GET)，请求资源(/Enterprise/detail.asp)，客户端IP地址(70.25.29.53)，用户浏览的前一个页面(http://www.example.com/searchout.asp)，状态码(202)，服务端发送字节数(17735)，从客户端接收字节数(369)以及花费时间（4656，单位为毫秒）。
```

常用的Web日志分析方法包括特征分析法和访问频率分析法。

特征分析法是指利用网络行为的日志记录特征，从而可以快速在日志中定位相关行为。网络攻击或者Webshell会有一些比较明显的特征，例如，SQL注入攻击的日志中会有union、select等字段；XSS攻击的日志中会有<script>、alert、eval等字段；文件上传需要重点关注upload、file等内容，一般在上传后的日志中会有一个带日期的页面，此时可能存在恶意上传。访问频率分析法就是根据一定时间内的访问频率来判断是哪种攻击方式，并实现对攻击者IP地址的溯源。当攻击者发起攻击时，一般会在短时间内发起大量网络请求。例如，当日志中出现大量HEAD方法请求时，很有可能是攻击者在进行扫描。HEAD请求只需要服务器返回头部信息，结合状态码等信息，即可知道资源在服务器中是否存在；或者是对同一个登录页面发出多次请求，那么可能是在爆破账号和密码。一般而言，当确定了服务器发生异常的时间段后，可以根据访问频率对IP地址排序，频率较高的IP地址可能就是攻击者的IP，这是一种不太精确但比较实用的方法。特征分析法和访问频率分析法不存在孰优孰劣的问题，很多时候两种方法会一起使用，日志分析类题目的关键在于读懂日志内容，掌握请求内部的代码功能和各请求之间的逻辑关系。如果读者的编程能力较强，可以考虑编写一些小程序来快速处理日志；如果读者对于Python等脚本语言不太熟悉，可以将Web日志导入到Excel或WPS中再做进一步分析。具体的导入方法为，在Excel或者WPS中单击“文件”，选择“打开”，再选择要分析的日志文件，如图1.3.1所示。选择“分隔符号”，单击“下一步”，只选择“空格”，再根据需求选择相应选项，即可导入成功。利用Excel或者WPS中自带的一些统计功能，可以快速完成日志分析。

##### 解题技巧

```
流量分析和日志分析是行业或企业CTF比赛时的重点题型。比赛实践表明，如果在比赛过程中对其他题目都无法下手，建议大家“死磕”这两个类型的题目。当这两类题目难度不大时，通过花费时间细致耐心地逐个查看，几乎都能发现题目中的关键点。所以，这类题目建议大家“逢题必做”，不要轻易选择放弃。
```

### SQLmap

在MySQL中，把information_schema看作一个数据库，确切说是信息数据库。其中保存着MySQL服务器维护的所有其他数据库的信息。information_schema库中有以下几个常见表。❑SCHEMATA表：提供当前MySQL实例中所有数据库的信息，命令show databases的结果来自此表。❑TABLES表：提供关于数据库中的表的信息（包括视图），详细描述了某个表属于哪个schema、表类型、表引擎、创建时间等信息，命令show tables from schemaname的结果来自此表。❑COLUMNS表：提供表中的列信息，详细描述了某张表的所有列以及每个列的信息，命令show columns from schemaname.tablename的结果就取自此表。需要特别说明的是，在MySQL中，table_schema是数据库的名称，table_name是具体的表名，table_type是表的类型。

SQLmap的注入流程大致如下：首先寻找注入点，并验证注入点的有效性；然后，利用注入点，通过逐字节爆破获取MySQL中所有的数据库名，字节爆破一般会采用二分查找法以加快速度；根据攻击者选择的数据库，再通过逐字节爆破获取该数据库中所有的表名；接着，根据攻击者选择的表，通过逐字节爆破以获取该表中所有的列名；最后，根据攻击者选择的列，通过逐字节爆破，以获取该表中所选择列的每一项具体值。

## 2.系统设备日志及分析方法

除了Web日志，操作系统和安全设备也会产生相应的日志。其中，比较常见的是Windows与Linux系统日志。在CTF比赛中，系统日志分析的题目相对较少。我们先介绍系统记录了哪些日志信息。

### 1).Linux日志

Linux系统的日志主要记录在/var/log目录下，常见的日志包括以下几种：

```
/var/log/messages

用于记录系统相关信息，如执行程序、系统错误、启动信息等。一般使用messages日志查看可疑程序执行的可疑操作、系统在执行程序时出现的错误等。记录格式为：日期　时间　主机　执行程序名称[进程ID]
```

```
/var/log/boot.log

用于记录系统启动信息的日志，一般用于查看系统启动时的所有相关信息
```

```
/var/log/lastlog

用于记录用户近期的登录情况，直接查看lastlog文件可能信息不易识别，也可以使用lastlog命令进行查看
```

```
/var/log/cron

保存Linux的计划任务相关信息的日志，可以用它来寻找攻击者可能会写入的一些恶意计划任务，其中可能会带有恶意软件的相关信息。cron日志有比较重要的作用，在CTF比赛中可以优先排查。其记录格式为：日期　时间　主机　运行任务的程序[进程号]任务运行的具体信息
```

```
/var/log/secure

Linux的安全日志，主要用于记录用户登录服务器以及安全相关的信息。一些服务，如polkitd、login、sshd等，无论登录成功与否，均会被记录到此日志中，所以可以通过它来判断服务器是否被攻击（如暴力破解、调用一些系统方法等）
```

| 日志路径                               | 功能                                             |
| -------------------------------------- | ------------------------------------------------ |
| /var/log/faillog                       | 记录用户登录失败信息(包括错误登录命令)           |
| /var/log/btmp                          | 记录所有失败登录信息                             |
| /var/log/lastlog                       | 记录所有用户最近登录的信息                       |
| /var/log/user.log                      | 记录所有用户信息                                 |
| /var/log/daemon.log                    | 记录系统后台守护进程日志信息                     |
| /var/log/wtmp         /var/log/utmp    | 永久记录每个用户登录、注销及系统启动、停机的事件 |
| /var/log/httpd/  /var/log/apache2      | 记录服务器 access log和error log 的信息          |
| /var/log/maillog     /var/log/mail.log | 记录电子邮件服务的日志信息                       |
| /var/log/mail/                         | 这个子目录包含邮件服务的额外日志                 |
| /var/log/samba/                        | 记录由sammba存储的信息                           |

### 2).win日志

Windows系统也记录了非常详细的系统日志，不过我们可能平时没有注意到。Windows系统日志一般可以在事件查看器中进行查看，通常分为五类：应用程序、安全、Setup、系统、转发事件，其中又以系统日志、安全日志和应用程序日志更为常用。

事件查看器的打开方式为：打开控制面板，选择“系统和安全”，在“管理工具”中选择“查看事件日志”

```
系统日志
该日志包含Windows系统组件记录的事件，包括错误、警告及任何应用程序需要报告的信息等，该日志保存在System.evtx文件中

安全日志
Windows的安全日志和Linux的安全日志相似，包含用户登录情况、用户访问时间以及访问是否授权等，并详细记录了使用者信息、登录类型、登录失败的账户、失败信息、进程信息、内网信息以及详细身份验证信息等。该日志在操作系统中保存在Security.evtx文件下。

应用程序日志
应用程序日志记录了应用程序的运行情况，包括运行出错及出错的原因。通过这些信息，可以进行对应的故障排查。该日志保存在Application.evtx文件中。
```

关于系统设备日志的分析，目前并没有一套通用的方法，大家可以借鉴Web日志的分析方法，但主要还是依靠熟能生巧，这类日志看得越多，分析起来就越熟练。在Linux系统下，可以结合特征分析法和访问频率分析法，快速定位关键信息；在Windows系统下，可以通过仔细查看事件查看器、有效利用特征过滤等方式快速发现异常信息。

# 四.电子取证分析
## 1.电子取证的常用技术
### 1).文件识别技术
几乎所有电子取证题目都会提供一个文件，通常需要在没有后缀的情况下猜测这个文件的功能，此时我们要先识别文件类型。每个文件都有自己独特的文件格式，识别文件类型的本质是从文件头或文件尾发现文件格式的特征，根据特征判断文件类型。每种文件格式的文件头都有独特的设计，一般通过文件头即可识别文件类型，文件头的这一字段也叫作magic number（魔数或者幻数）。

​									常见的文件头特征

| 文件类型    | 文件头（十六进制）      |
| ----------- | ----------------------- |
| .jpg        | FF D8                   |
| .png        | 89 50 4E 47 0D 0A 1A 0A |
| .gif        | 47 49 46 38             |
| .bmp        | 42 4D                   |
| .zip        | 50 4B 03 04             |
| .rar        | 52 61 72 21             |
| .doc   .xls | D0 CF 11 EO             |
识别文件类型有两种方法：
	①利用十六进制编辑器手工查看文件头；
	②利用现成的工具判断文件类型。
### 2).strings命令
在对象文件或二进制文件中查找可打印的字符串，字符串是4个或更多可打印字符的任意序列，以换行符或空字符结束。
该命令的语法格式为：
```
strings [-a] [-] [-o] [-t Format] [-n Number] [-Number] [File...]

-a--all：扫描整个文件而不是只扫描目标文件初始化和装载段。
-f-print-file-name：在显示字符串前先显示文件名。
-n-bytes=[number]：找到并且输出所有NUL终止符序列。
-：设置显示的最少字符数，默认是4个字符。
-t--radix={o,d,x}：输出字符的位置，基于八进制、十进制或者十六进制。
-o：类似--radix=o。
-T--target=：指定二进制文件格式。
-e --encoding={s,S,b,l,B,L}：选择字符编码方式，s=7-bit（即ASCII码，默认方式）、S=8-bit、b=16-bit（大端）、l=16-bit（小端）、B=32-bit（大端）、L=32-bit（小端）。
```
### 3).binwalk命令
binwalk命令用于识别嵌入固件镜像的文件和代码。但在CTF比赛中，它的使用更加广泛，可以根据文件头魔数来识别和提取对象文件中的其他文件，因此成为取证、隐写等题目的必用工具。binwalk命令的用法和file命令完全相同。当命令中没有任何选项时，binwalk只能检测（识别）对象中有哪些文件，检测结果有3列，第1列代表十进制，表示检测出的文件距离原文件开头的偏移字节数；第2列是第1列数对应的十六进制，第3列是对检测出来的文件的详细说明。图中的信息表示从原GIF文件中检测出6个zip压缩包，并说明了每个压缩包中包含的文件。

如果检测出的文件中有我们感兴趣的文件，那么需要将这些文件提取出来。“-e”选项可以根据默认的预定义配置文件extract.conf，自动从对象中提取文件。带“-e”选项的命令运行结果和图1.4.2完全一样，如果成功提取文件，就会在终端的执行目录下生成一个新文件夹，文件夹的名字是：“_”+对象名字+“.extracted”。从对象中提取出来的文件都会保存到这个文件夹，这里有个细节需要注意，文件夹生成的位置和终端运行时所在的路径有关，建议在运行binwalk命令前将所在路径设置为桌面。

## 2.文件恢复

常见的文件恢复题目包含以下几种：文件头损坏修复；文件被拆分为若干片段，需要拼接复原；根据临时文件或者中间文件恢复原文件；恢复被删除文件等。

文件头修复和文件拼接复原的原理是一样的，都需要熟练掌握不同文件的文件格式。通过残留的文件格式信息可以确定文件类型，然后通过修复文件头部使文件正常打开。

## 3.磁盘取证分析方法

在一般的数据取证工作中，为了保全证据，在获取证据介质后，首先要做的就是对介质数据进行全盘镜像备份。在制作完镜像备份后，接下来要做的就是对镜像进行数据提取了。在CTF比赛中，磁盘取证类题目一般会提供一个磁盘镜像，选手要综合利用磁盘存储和文件系统的知识来提取磁盘镜像文件中的flag。

文件系统是一种存储和组织计算机数据的方法，可以方便地访问和查找文件数据。文件系统使用**文件和树形目录**的抽象逻辑概念代替了硬盘和光盘等物理设备使用的数据块的概念。用户使用文件系统来保存数据，不必关心数据实际保存在硬盘（或者光盘）的数据块上的地址，只需要记住这个文件所属的目录和文件名即可。

文件数据除了文件的实际内容外，还包含**文件权限(RW X)与文件属性（所有者、群组、时间参数等）**。

在Linux系统下，文件系统通常会把这两部分数据放到不同的块，权限与属性放置到inode中，实际数据则放置到数据块(block)中。另外，还有一个Superblock会记录文件的整体信息，包括inode与block的总量、使用量、剩余量等，每个inode和block都有编号。

这三个数据的意义简要说明如下：

```
Superblock：记录文件的整体信息，包括inode与block的总量、使用量、剩余量，以及文件系统的格式与相关信息等。

inode：记录文件的属性，一个文件占用一个inode，同时记录此文件的数据所在的block号。

block：实际记录文件的内容，若文件太大，会占用多个block。
```

常见的磁盘镜像格式如下：

```
Windows：FAT12、FAT16、FAT32、NTFS

Linux：EXT2、EXT3、EXT4
```

不同格式的文件系统在读取文件时的方法也不尽相同。例如，对于EXT2和EXT3格式的磁盘镜像，如图1.4.6所示，文件系统先格式化出inode（较小的长方形）与block（较大的长方形）的区块，假设某一个文件的属性与权限数据被放置到inode4，而这个inode记录了文件数据的实际放置点为2,7,13,15这四个block，操作系统根据文件的inode信息排列读取顺序，然后一次性读出4个block的内容。

文件系统读文件数据

![image-20240725200532240](D:/%E6%96%87%E6%A1%A3/%E7%AC%94%E8%AE%B0/CTF/image-20240725200532240.png)

### 文件雕复技术

文件雕复(File Carving)是电子取证中经常使用的一种文件恢复技术，它从表面上无差别的二进制数据集（即原始磁盘映像）中提取或恢复文件，而不是利用磁盘映像的文件系统类型。这个过程就如同在一块光滑的石头上雕刻出许多图案一样，这也是“文件雕复”这个名字的由来。其本质仍然是基于格式分析的文件识别和恢复，通常需要扫描原始字节，检查文件头和文件尾并将其排序。

## 4.内存取证分析方法

volatility的语法：

```kali
volatility -f <文件名> --profil=<配置文件> <插件> [插件参数]

<插件>部分的常用插件选项包括：❑imageinfo：显示目标镜像的摘要信息，知道镜像的操作系统后，就可以在--profile中带上对应的操作系统。❑pslist：该插件列举出系统进程，但它不能检测出隐藏的进程。❑psscan：可以找到先前已终止的进程以及被rootkit隐藏的进程。❑pstree：以树的形式查看进程列表，和pslist一样，它也无法检测出隐藏的进程。❑mendump：提取出指定的进程。❑filescan：扫描所有文件列表。❑hashdump：查看当前操作系统中的password hash，例如Windows的SAM文件内容。❑svcscan：扫描Windows的服务。❑clipboard：查看系统剪贴板中的信息。❑connscan：查看网络连接。❑lsadump：从注册表中提取出已解密的LSA密钥信息。LSA是Windows系统本地安全认证的模块，它会存储用户登录其他系统和服务时所使用的用户名和密码。❑procdump：将进程转储为一个可执行文件。❑memdump：转储进程的可寻址内存。

除了上述自带的一些插件，Volatility还提供了插件社区项目，地址为https://github.com/volatilityfoundation/community，但这个项目没有给出详细说明。每个文件夹是插件制作者的姓名，文件夹内才是插件真正的名称。插件的安装和使用方法见项目内的描述，这里我们介绍一些社区插件：❑mimakatz：提取内存中的密码，使用前需要安装依赖sudo pip install construct==2.5.5-reupload，作者是Francesco Picasso。❑ndispktscan：搜索内核的网络流量包信息，作者是Adam Bridge。❑chrome_ragamuffin：分析内存中的Chrome浏览器运行实例，可以分析正在浏览的页面，作者为Alessandro DeVito。❑rdpkeys：分析Windows RDP远程连接的数据，提取密钥，可配合Wireshark对抓取的RDP流量解密，作者为Bartosz Inglot。❑powersh：对内存中（隐藏）的powershell进程进行分析，作者是Cesare Pizzi。

❑lastpass：从浏览器内存空间中读取账户密码信息，作者是Kevin Breen。❑bitlocker：提取BitLocker全卷加密密钥(FVEK)，可以用来解密BitLocker卷，只支持Windows Vista/7，作者是Marcin Ulikowski。❑volatility-bitlocker：bitlocker的同类插件，支持Windows7/8/10。
```

作用是根据进程号(PID)提取某个进程，其中的memdump可以换成procdump。通过Volatility自带插件pslist可以查看进程信息，如果存在可疑或需要重点关注的进程，通过上述命令就可以将进程提取出来，再利用binwalk、strings等命令可以对提取出的进程做进一步分析

```shell
python vol.py-f 文件 --profile=XXX memdump-p [PID] -D [dump出的文件保存的目录]
```

# 五.压缩文件格式破解

## 1.ZIP压缩包格式

一个ZIP压缩文件由如下三部分组成：压缩源文件数据区、压缩源文件目录区和压缩源文件目录结束标志。具体而言，一个ZIP文件可以按如下方式分解：

```
[本地文件头+文件数据+数据描述符]{1,n}+目录区+目录结束标识

[本地文件头+文件数据+数据描述符]构成压缩源文件数据区，
{1，n}表示这部分数据最少出现1次，也可以出现n次，n的数量和压缩前的文件数量一致。目录区（也称为核心目录）会保存压缩前文件和文件夹的目录信息，这部分数据一般均为明文显示。
目录结束标识存在于整个压缩包的结尾，用于标记压缩的目录数据的结束。
```

### 1).压缩源文件数据区

这一部分记录压缩的所有文件的内容信息，每个压缩文件都由三部分组成，包括本地文件头、文件数据（已压缩）和数据描述符。该数据区中每一个压缩的源文件/目录都是一条记录(record)。

通用比特标志位占16比特，其中第0比特，即最低比特（也就是所占2字节的最右比特），代表文件是否被加密。也就是说，如果这2字节所代表的数是奇数就说明文件被加密。当通用比特标志位的第3比特为1时，数据描述符才会在ZIP文件中出现，数据描述符紧接在文件数据后。数据描述符只有在不能对输出的ZIP文件进行检索时才会被使用，例如在一个不能检索的驱动器（如磁带机）上的ZIP文件就会包含数据描述符；如果是保存在磁盘上的ZIP文件，则一般没有数据描述符。



| 偏移 | 大小(字节) | 描述                                                         |
| ---- | ---------- | ------------------------------------------------------------ |
| 0    | 4          | 数据区文件头标识，50 4B 03 04                                |
| 4    | 2          | 解压文件所需pkware 的最低版本                                |
| 6    | 2          | 通用比特标志位，也称为全局方式位标记，说明文件是否加密等信息 |
| 8    | 2          | 压缩方式                                                     |
| 10   | 2          | 文件最后修改时间                                             |
| 12   | 2          | 文件最后修改日期                                             |
| 14   | 4          | 压缩前文件的CRC32                                            |
| 18   | 4          | 压缩后大小(单位:字节)                                        |
| 22   | 4          | 未压缩大小(单位:字节)                                        |
| 26   | 2          | 文件名长度(单位:字节)                                        |
| 28   | 2          | 扩展区长度(单位:字节)                                        |
| 30   | n          | 文件名                                                       |
| 30+n | n          | 扩展区                                                       |

​								本地文件头的格式

### 2).压缩源文件目录区

这个区域也称为核心目录，记录了压缩前所有文件和文件夹的目录结构信息。在这个数据区中，每一条记录对应着压缩源文件数据区中的一条数据。

| 偏移   | 大小(字节) | 描述                             |
| ------ | ---------- | -------------------------------- |
| 0      | 4          | 日录区文件头标识，50  4B  01  02 |
| 4      | 2          | 压缩所用的pkware 版本            |
| 6      | 2          | 解压所需pkware的最低版本         |
| 8      | 2          | 全局方式位标记                   |
| 10     | 2          | 压缩方式                         |
| 12     | 2          | 文件最后修改时间                 |
| 14     | 2          | 文件最后修改日期                 |
| 16     | 4          | CRC32                            |
| 20     | 4          | 压缩后大小(字节)                 |
| 24     | 4          | 未压缩大小(字节)                 |
| 28     | 2          | 文件名长度(n字节)                |
| 30     | 2          | 扩展区长度(m字节)                |
| 32     | 2          | 文件注释长度(k字节)              |
| 34     | 2          | 文件开始位置的磁盘编号           |
| 36     | 2          | 内部文件属性                     |
| 38     | 4          | 外部文件属性                     |
| 42     | 4          | 本地文件头的相对偏移             |
| 46     | n          | 目录文件名                       |
| 46+n   | m          | 扩展区                           |
| 46+n+m | k          | 文件注释内容                     |

目录区格式





















































































































































# 六.信息搜集和搜索引擎的高级用法